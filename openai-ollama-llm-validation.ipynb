{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "# Read the app.yaml file\n",
    "with open('config/app.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Load the API key from the yaml file\n",
    "OPENAI_API_KEY = config.get('openai-api-key')\n",
    "MODEL = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions or tasks you have. How can I assist you today?\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing openai connection with langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(api_key=OPENAI_API_KEY, model=MODEL)\n",
    "model.invoke(\"Hello, how are you? This is a test message.\")\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "chain = model | parser\n",
    "chain.invoke(\"Hello, how are you? This is a test message.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm doing well, thank you for asking. It's nice to meet you and I'll do my best to assist you with any questions or topics you'd like to discuss. Please feel free to ask me anything, from general knowledge to more in-depth conversations. How about you? Is there something on your mind that you'd like to chat about?\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing local llm - llama3.2\n",
    "from langchain_community.llms import Ollama\n",
    "model = Ollama(model='llama3.2') # Make sure llama3.2 is downloaded running locally\n",
    "model.invoke(\"Hello, how are you? This is a test message.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdfloader = PyPDFLoader('data/ConceptsofBiology-WEB.pdf')\n",
    "pages = pdfloader.load_and_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
